from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

from nltk.stem import SnowballStemmer
from entities import get_entities
from collections import defaultdict
from entities_functions import merge_entities
from elasticsearch import Elasticsearch
import matplotlib.pyplot as plt
from pymongo import MongoClient
from math import sqrt,log
import re

from rocchio import get_rocchio_keywords

'''
Given a list of articles, 
perform Named Entity Recognition and
return a list of dictionaries containing information about the entities found
'''
def article2entities(articles,index):
    i = 0
    entities = {}
    for (body,weight,article_id) in articles[0:10000]:
        i+=1
        print ' Article {} out of {}'.format(i,len(articles))
        for (entity_name,entity_dict) in get_entities(body,index).items():

            # Update the aggregated dict. 

            freq = entity_dict['freq']
            aliases = entity_dict['aliases']

            # If the entity has already been found for this bill, update the existing instance.
            # Otherwise create a new instance.
                        
            if entity_name in entities:
                entities[entity_name]['articles'].append(article_id)
                entities[entity_name]['freq']+=freq
                entities[entity_name]['weight']['articles'].append({'article_weight':weight,'article_ranking':i,'article_id':article_id,'frequency':freq})
                entities[entity_name]['weight']['value']+=weight*1
                
                # Merge tag counts.

                for (tag,count) in entity_dict['tags'].items():
                    if tag in entities[entity_name]['tags']:
                        entities[entity_name]['tags'][tag]+=count
                    else:
                        entities[entity_name]['tags'][tag]=count

                # Merge aliases list.

                for alias in aliases:
                    if alias not in entities[entity_name]['aliases']:
                        entities[entity_name]['aliases'].append(alias)
            else:
                entities[entity_name] = {}
                entities[entity_name]['articles'] = [article_id]
                entities[entity_name]['freq']=freq
                entities[entity_name]['name']=entity_name
                entities[entity_name]['weight']={}
                entities[entity_name]['tags'] = entity_dict['tags']
                entities[entity_name]['weight']['value']=weight*1
                entities[entity_name]['weight']['articles']=[{'article_weight':weight,'article_ranking':i,'article_id':article_id,'frequency':freq}]
                entities[entity_name]['aliases'] = aliases
    return entities.values()

'''
Given a list of dictionaries of entities and a collection, insert/update them in MongoDB and
set a 'mongoid' attribute in the dictionary with the corresponding MongoDB id.
'''
def insert_entities(entities,collection,bill_id):
    i = 0
    for entity in entities:
        i+=1
        
        # Create a Mongo Entity instance based on the entity.

        mongo_entity = {}
        mongo_entity['name'] = entity['name']
        mongo_entity['aliases'] = entity['aliases']
        mongo_entity['bills'] = [bill_id]
        mongo_entity['tags'] = entity['tags']

        res = collection.find({'name':entity['name']})
        # Insert or update.
        if res.count()>0:
            if res.count()>1:
                raise Exception('Non unique entity')

            merge_entities(mongo_entity,{'name':mongo_entity['name']},collection)

        else:
            # Create a new mongo document containing the name and aliases and fetch the id.
            collection.insert(mongo_entity)

        # We need to store the mongo_id in the dictionary for linking the bill to the entity.
        res = collection.find({'name':entity['name']})
        entity['mongoid'] = res[0]['_id']

    return entities


def get_norm(v):
    return sqrt(v[0]**2 + v[1]**2)

def find_cutting_point(scores):
    distances = []
    #print scores
    max_y = scores[0]
    b = [len(scores),scores[len(scores)-1]-max_y]
    b_norm = get_norm(b)
    b[0] = b[0]/b_norm
    b[1] = b[1]/b_norm

    for i in range(0,len(scores)):
        p = (i,scores[i]-max_y)
        p_bhat = p[0]*b[0] + p[1]*b[1]
        proj = (b[0]*p_bhat,b[1]*p_bhat)
        d = (p[0]-proj[0],p[1]-proj[1])
        distances.append(get_norm(d))

    return distances.index(max(distances))

def relate_entities_bills(entities,collection,bill_id):
    bill_entities = []
    for entity in entities:
        bill_entity = {}
        bill_entity['entity'] = entity['mongoid']
        bill_entity['weight'] = entity['weight']
        bill_entity['freq'] = entity['freq']
        bill_entity['name'] = entity['name']
        bill_entity['bill'] = bill_id
        collection.insert(bill_entity)

def relate_entities_documents(entities,collection,bill_id):
    for entity in entities:
        for article in entity['articles']:
            collection.insert({'entity': entity['mongoid'], 'article': article,'bill_id':bill_id})

def main():
    conn = MongoClient()
    db = conn.catalan_bills

    bills = []
#for bill in db.bills.find():
    for bill in db.bills.find():
        if int(bill['year'])>=2014:
            bills.append(bill)

    print ('Processing: {}'.format(len(bills)))
    for bill in bills:

        original_keywords = bill['keywords']
        #print bill['text'][0:1000].encode('utf8')
        #print bill['keywords']

       
        # Get rocchio's keywords.

        rocchio_kws = get_rocchio_keywords(original_keywords)

        # Store them in Mongo.
        
        db.bills.update({'id':bill['id']},{'$set':{'rocchio_keywords':rocchio_kws}})


        # Execute the new query.

        query = {"query":{"bool":{"disable_coord": True,"should": [{'match_phrase':{'body':{'query':kw,'boost':weight,'analyzer':'analyzer_keywords'}}} for [kw,weight] in rocchio_kws[0:10]]}}}

        print 'Searching'
        es = Elasticsearch(timeout=100)

        results = es.search(index="catnews_spanish", explain = True, body=query,search_type = 'dfs_query_then_fetch',size =3000,sort='_score:desc,_id:desc')

        document_keywords = document2keywords(results)

        articles = [(x['_source']['body'],x['_score'],x['_id']) for x in results['hits']['hits']]

        num_articles = find_cutting_point([(y,_id) for (_,y,_id) in articles])
        print bill['id']
        r_articles_ids = [x['_id'] for x in results['hits']['hits']]
        db.bills.update({'id':bill['id']},{'$set':{'bill_articles_ids':r_articles_ids}})
        continue
        print('Bill: {}'.format(bill['id']))

        print(' Found {} relevant articles'.format(num_articles))

        print(' Finding entities')
        entities = article2entities(articles[0:num_articles],'catnews_spanish')
        print(' Found {} entities'.format(len(entities)))
            
        print(' Inserting entities')
        entities = insert_entities(entities,db.entities,bill['id'])

        print(' Relating entities with bills')
        relate_entities_bills(entities,db.entities_bills,bill['id'])

        print(' Relating entities with documents')
        relate_entities_documents(entities,db.entities_documents,bill['id'])

        print(' Relating entities with keywords')
        relate_entities_keywords(entities,db.entities_keywords,document_keywords,bill['id'])

main()
